{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680df422-7c33-4e22-9f3c-ebe57f46f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code compute preliminary statistical analyses on RS CLOSED DATA\n",
    "# 1) Descriptive statistics\n",
    "# 2) Linear mixed model on every region with group and resting state block as fixed effects, and subject ID as random effect\n",
    "# 3) Clustering of ASD subject based on general IQ\n",
    "# 2) Linear mixed model on every region with IQ-based subgroups and resting state block as fixed effects, and subject ID as random effect\n",
    "\n",
    "\n",
    "# Import libraries and set directories\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# environment name: explore_cmifoof\n",
    "\n",
    "# Set paths\n",
    "main = ''\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(os.path.join(main,\"rs_closed_alpha_regions_AllBlocks.csv\"))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72000164-647b-469f-b406-528ec4532331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter of interest\n",
    "\n",
    "parameter = \"alpha_amplitude\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e98a34-08bf-4916-829e-0cfe73b46f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load infos about EEG montage and display regions channels\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Load and display an image\n",
    "image_path = os.path.join(main, \"EEG_regions_electrodes.png\") # Update this to the path of your image file\n",
    "display(Image(filename=image_path))\n",
    "\n",
    "\n",
    "# Read channel dictonaries, defining for each area the number of the electrodes\n",
    "channel_dict = {\n",
    "        \"frontal_left\": [23, 24, 27, 28],\n",
    "        \"frontal_midline\": [5, 11, 12, 16],\n",
    "        \"frontal_right\": [3, 117, 123, 124],\n",
    "        \"central_left\": [ 35, 36, 41, 42],\n",
    "        \"central_midline\": [7, 31, 80, 106],\n",
    "        \"central_right\": [93, 103, 104, 110],\n",
    "        \"posterior_left\": [51, 52, 59, 60],\n",
    "        \"posterior_midline\": [62, 71, 72, 76],\n",
    "        \"posterior_right\": [85, 91, 92, 97]\n",
    "                 }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8039625-0ed3-4551-94c5-42a307e5fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute descriptive statistics\n",
    "\n",
    "asd_data = data[data['diagnosis']==\"ASD\"]\n",
    "td_data = data[data['diagnosis']==\"TD\"]\n",
    "\n",
    "for region in channel_dict.keys():\n",
    "\n",
    "    # Get the name of each region\n",
    "    region_column = f\"{parameter}_{region}\"\n",
    "    \n",
    "    asd_data_region = asd_data[region_column]\n",
    "    td_data_region = td_data[region_column]\n",
    "\n",
    "    # Print values\n",
    "    print(f\"Mean value for {region_column} in ASD is {asd_data[region_column].mean()}\")\n",
    "    print(f\"Mean value for {region_column} in TD is {td_data[region_column].mean()}\")\n",
    "    print(f\"Standard Deviation for {region_column} in ASD is {asd_data[region_column].std()}\")\n",
    "    print(f\"Standard Deviation for {region_column} in TD is {td_data[region_column].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8148b91-74be-406a-aea2-09ed6ce2d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every region:\n",
    "# 1) Plot case-control differences in the parameter\n",
    "# 2) Compute for every region the correlation between parameter value and FIQ in ASD group.\n",
    "#    This is done to explore the hypothesized association between alpha amplitude and cognitive development in Autism.\n",
    "\n",
    "for region in channel_dict.keys():\n",
    "\n",
    "    region_column = f\"{parameter}_{region}\"\n",
    "\n",
    "    # Plot boxplot\n",
    "    data.boxplot(column=region_column, by='diagnosis')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot scatter \n",
    "    plt.scatter(asd_data[region_column], asd_data['fiq'])\n",
    "    plt.title('Correlation between alpha region amplitude and IQ in Autism')\n",
    "\n",
    "    # Remove NA\n",
    "    asd_data_clean = asd_data.dropna(subset=[region_column, 'fiq'])\n",
    "\n",
    "    # Compute pearson correlation\n",
    "    r_pears = stats.pearsonr(asd_data_clean[region_column], asd_data_clean['fiq'])\n",
    "    print(r_pears)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f993b4-6f71-41b7-b7f6-f12c10d4c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every region compute a mixed linear model with diagnosis and rs time point (1,2,3,4,5) as fixed effect and subject \n",
    "# as random effect\n",
    "from statsmodels.formula.api import mixedlm\n",
    "\n",
    "for region in channel_dict.keys():\n",
    "  \n",
    "    # Get region name\n",
    "    region_column = f\"{parameter}_{region}\"\n",
    "    filtered_data = data[data[region_column].notnull()] # Remove missing values\n",
    "\n",
    "    # Generate formula and model\n",
    "    model_formula = f\"{region_column} ~ diagnosis * rs_block\"\n",
    "    model = mixedlm(model_formula, filtered_data, groups=filtered_data[\"subid\"])\n",
    "\n",
    "    # Fit the model\n",
    "    result = model.fit()\n",
    "\n",
    "    # Print the summary of the model\n",
    "    print(region_column)\n",
    "    print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521f45c2-42b2-40ff-952a-037d5cb34420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, I want to explore full scale iq data distribution for the two groups.\n",
    "# If ASD show a multiple-peak density distribution, I'm proceeding with subgrouping them based on IQ.\n",
    "\n",
    "# Custom color palette\n",
    "custom_palette = {'ASD': 'blue', 'TD': 'green'}\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data, x='fiq', hue='diagnosis', kde=True, bins=10, palette=custom_palette, element='step', stat='density')\n",
    "\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('IQ')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Histogram of IQ Scores by Group')\n",
    "plt.legend(title='Diagnosis')  # LP: legend showing up empty - maybe issue with my package?\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b5c7d-4bbd-4c4d-b228-07129d5a0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASD iq data show two peaks.\n",
    "# Now, I'm perform k-means clustering (k-optimal = 2) to autism cluster subjects based on IQ\n",
    "# LP: I am not very sure about clustering 1D data. You would really need to prove multiple peaks in the data distribution\n",
    "# beforehand, and this was not super clear from the histogram above - otherwise you just split continuous data into arbitrary groups!\n",
    "# But this is not Python, sorry if I'm wrong :)\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Filter the data to include only the ASD group\n",
    "asd_data = data[data['diagnosis'] == 'ASD']\n",
    "asd_data = data[data['fiq'].notnull()] \n",
    "\n",
    "\n",
    "# Get all subjects IQ\n",
    "fiq_scores = asd_data[['fiq']]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "fiq_scores_scaled = scaler.fit_transform(fiq_scores)\n",
    "\n",
    "# Determine the number of clusters using the elbow method\n",
    "sum_of_squared_distances = []\n",
    "K = range(1, 10)\n",
    "\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans = kmeans.fit(fiq_scores_scaled)\n",
    "    sum_of_squared_distances.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Sum of squared distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()\n",
    "\n",
    "# From the elbow plot, choose an appropriate number of clusters (e.g., 3)\n",
    "optimal_k = 4\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=optimal_k)\n",
    "clusters = kmeans.fit_predict(fiq_scores_scaled)\n",
    "\n",
    "# Add the cluster labels to the original data\n",
    "asd_data['Cluster'] = clusters\n",
    "\n",
    "# Visualize the clusters\n",
    "# LP: since you're clustering 1D data, a better visualization would have been the histograms\n",
    "# for each cluster.\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='fiq', y='Cluster', data=asd_data, hue='Cluster', palette='viridis', s=100)\n",
    "plt.xlabel('fiq')\n",
    "plt.ylabel('Cluster')\n",
    "plt.title('Clusters of ASD Group Based on full scale IQ')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561a02f1-6729-4a07-a5a3-83a10221a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show clusters and their FIQ pattern\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Cluster', y='fiq', data=asd_data, palette='husl')\n",
    "\n",
    "asd_data['Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb82483b-c55c-438b-a3ad-d007c84e2cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give labels to clusters\n",
    "asd_data['FIQ_subgroup'] = asd_data['Cluster'].map({0: 'HIGH', 1: 'LOW', 2: 'VERY_HIGH', 3:'VERY_LOW'})\n",
    "\n",
    "# Add fake cluster label also to TD group\n",
    "td_data['Cluster'] = 85 #arbitrary number to fill the column\n",
    "td_data['FIQ_subgroup'] = \"TD\"\n",
    "\n",
    "# Concatenate vertically ASD and TD dataframe (stack rows)\n",
    "all_data_subgroups = pd.concat([asd_data, td_data], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a09d5198-a071-4773-b601-3b00c3a48b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize function to compute pairwise comparisons\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "\n",
    "def pairwise_comparisons(coefficients, std_errors, labels):\n",
    "    num_groups = len(coefficients)\n",
    "    comp_results = []\n",
    "    for i in range(num_groups):\n",
    "        for j in range(i + 1, num_groups):\n",
    "            # Difference in coefficients\n",
    "            effect_diff = coefficients[i] - coefficients[j]\n",
    "            # Standard error of the difference\n",
    "            se_diff = np.sqrt(std_errors[i]**2 + std_errors[j]**2)\n",
    "            # Z-score\n",
    "            z = effect_diff / se_diff\n",
    "            # Two-tailed p-value\n",
    "            p_value = 2 * (1 - stats.norm.cdf(np.abs(z)))\n",
    "            comp_results.append((labels[i], labels[j], effect_diff, se_diff, z, p_value))\n",
    "    return comp_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e00829-ae1b-4664-8116-5306004dd11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every region compute a mixed linear model with FIQ subtype and rs time point (1,2,3,4,5) as fixed effect and subject \n",
    "# as random effect\n",
    "# LP: numpy import was missing! after you're done with a notebook always try to restart it and try to run all cells to see if everything works\n",
    "import numpy as np \n",
    "\n",
    "# LP: am I right in assuming you are comparing an unsplit population (TD) with a split population (ASD)?\n",
    "# I do not think this is sound if true!\n",
    "for region in channel_dict.keys():\n",
    "\n",
    "    \n",
    "    region_column = f\"{parameter}_{region}\"\n",
    "    filtered_data = all_data_subgroups[all_data_subgroups[region_column].notnull()]\n",
    "\n",
    "    model_formula = f\"{region_column} ~ FIQ_subgroup * rs_block\"\n",
    "    model = mixedlm(model_formula, filtered_data, groups=filtered_data[\"subid\"])\n",
    "\n",
    "    # Fit the model\n",
    "    result = model.fit()\n",
    "\n",
    "    # Print the summary of the model\n",
    "    print(region_column)\n",
    "    print(result.summary())\n",
    "\n",
    "    #\n",
    "    coefficients = result.fe_params[1:5]\n",
    "    std_errors = result.bse_fe[1:5]\n",
    "\n",
    "    labels = ['LOW', 'TD', 'VERY_HIGH', 'VERY_LOW']\n",
    "\n",
    "    # Perform pairwise comparisons\n",
    "    comparisons = pairwise_comparisons(coefficients, std_errors, labels)\n",
    "\n",
    "    # Print results\n",
    "    for comp in comparisons:\n",
    "        print(f\"Comparison: {comp[0]} vs {comp[1]}\")\n",
    "        print(f\"  Effect Difference: {comp[2]:.3f}\")\n",
    "        print(f\"  SE Difference: {comp[3]:.3f}\")\n",
    "        print(f\"  Z-Score: {comp[4]:.3f}\")\n",
    "        print(f\"  P-Value: {comp[5]:.3f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33926d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
